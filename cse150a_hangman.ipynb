{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ISETs9CGr-Vy",
        "outputId": "a821b1ba-8d5b-4338-fa70-9043edab0cdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hw1'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 55 (delta 26), reused 28 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (55/55), 723.52 KiB | 13.15 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ]
        }
      ],
      "source": [
        "# If cloning is needed -- i.e., if hangman.py and word counts are not already\n",
        "# available in file, you can run this\n",
        "!git clone https://github.com/ucsd-cse150a-w25/hw1.git\n",
        "!cp hw1/hangman.py hangman.py\n",
        "!cp hw1/hw1_word_counts_05.txt hw1_word_counts_05.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OFmQKsfZr-V0",
        "outputId": "d43b1185-2109-4f6d-8529-8f74aead448d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "  +---+\n",
            "      |\n",
            "      |\n",
            "      |\n",
            "     ===\n",
            "\n",
            "Word: _ _ _ _ _\n",
            "Tried letters: \n",
            "Game over! The word was:  THEIR\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from hangman import hangman_game\n",
        "\n",
        "# Play the game by yourself\n",
        "hangman_game()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0T6zkGQr-V1"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def random_inference(\n",
        "    letters_tried: set[str],\n",
        "    word_pattern: list[str],\n",
        "    word_counts: dict[str, int]\n",
        ") -> str:\n",
        "    '''\n",
        "    Random inference for playing hangman. This should be a simple method which returns a letter\n",
        "    that is NOT in letters_tried but any other letter, at random.\n",
        "\n",
        "    Hint: use the random.choice method\n",
        "    '''\n",
        "    # TODO: Implement random inference code to guess hangman\n",
        "    return ''\n",
        "\n",
        "hangman_game(random_inference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CGmWBdsXM4cN",
        "outputId": "c1376493-315b-4dab-ccf3-bbd0bbba1cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-9-ab53edfc4eda>, line 60)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-ab53edfc4eda>\"\u001b[0;36m, line \u001b[0;32m60\u001b[0m\n\u001b[0;31m    elif\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "def getPW(\n",
        "        word: str,\n",
        "        word_counts: dict[str, int]\n",
        ") -> float:\n",
        "\n",
        "  totalCount = 0\n",
        "  wordCount = 0\n",
        "\n",
        "  for item in word_counts.items():\n",
        "    totalCount += item.value()\n",
        "    if(item.key() == word):\n",
        "      wordCount += item.value()\n",
        "\n",
        "  return wordCount/totalCount\n",
        "\n",
        "def bayesianProbability(\n",
        "        currLetter: str,\n",
        "        currWord: str,\n",
        "        currCount: int,\n",
        "        totalCount: int,\n",
        "        word_pattern: list[str],\n",
        "        letters_tried: set[str],\n",
        "        word_counts: dict[str, int]\n",
        ") -> float:\n",
        "\n",
        "  # First calculation P(W=w | E):\n",
        "\n",
        "  # Numerator:\n",
        "  # P(W = w):\n",
        "  pw = currCount / totalCount\n",
        "  # P(E|W)\n",
        "  #check word_pattern matches currWord\n",
        "  #check failed_guesses are NOT in the word\n",
        "  failed_guesses = letters_tried - set(word_pattern)\n",
        "  index = 0\n",
        "  for index in range(0, 6):\n",
        "    if currWord[index] ==  word_pattern[index] or word_pattern[index == \"\"]:\n",
        "      pew = 1\n",
        "    else:\n",
        "      pew = 0\n",
        "    break\n",
        "\n",
        "  # Denominator\n",
        "  # SUM P(E|'W)\n",
        "  probSum = 0\n",
        "  for word in word_counts.keys():\n",
        "    for index in range(0, 6):\n",
        "      if word == currWord:\n",
        "        break\n",
        "      elif word[index] ==  word_pattern[index] or word_pattern[index == \"\"]:\n",
        "        probSum += 1\n",
        "      else:\n",
        "        break\n",
        "  # SUM P('W)\n",
        "  for word in word_counts.keys():\n",
        "    if currWord != word:\n",
        "      pNotW = 1 - getPW(word, word_counts)\n",
        "\n",
        "  # Second Term:\n",
        "\n",
        "\n",
        "  return 0\n",
        "\n",
        "def bayesian_inference(\n",
        "    letters_tried: set[str],\n",
        "    word_pattern: list[str],\n",
        "    word_counts: dict[str, int]\n",
        ") -> str:\n",
        "    '''\n",
        "    Bayesian inference method for playing hangman. The parameters given are as follows:\n",
        "\n",
        "    - letters_tried (set[str]): A set of strings which consist of all the letters that have already\n",
        "        been tried. For example, if 'A', 'E' has been guessed, `letters_tried = {'A', 'E'}`\n",
        "    - word_pattern (list[str]): A list of single characters that describe the current guess state.\n",
        "        For example, if the hangman state is _AB__, `word_pattern = ['_', 'A', 'B', '_', '_']`\n",
        "    - word_counts (dict[str, int]): The word counts dictionary which contains all possible 5 letter\n",
        "        words in our hangman game and their respective counts. For example, a key value pair could\n",
        "        be 'AARON': 413.\n",
        "    Return type: a single character string as your next best guess.\n",
        "    '''\n",
        "    # TODO: Implement inference code to play hangman optimally\n",
        "\n",
        "    alphabet = set(string.ascii_uppercase)\n",
        "\n",
        "    letters_left = list(alphabet - letters_tried)\n",
        "\n",
        "    if not letters_left:\n",
        "        raise ValueError(\"No letters left to guess!\")\n",
        "\n",
        "    maxProbability = 0\n",
        "    totalCount = 0\n",
        "    chosen_letter = \"a\"\n",
        "\n",
        "    #get total amount of words\n",
        "    for count in word_counts.values():\n",
        "      totalCount += count\n",
        "\n",
        "    for currLetter in letters_left:\n",
        "      for currWord, currCount in word_counts.items():\n",
        "        # Add current evidence E as parameter\n",
        "        # E: word_pattern + letters_tried\n",
        "        currProb = bayesianProbability(currLetter, currWord, currCount, totalCount, word_pattern, letters_tried, word_counts)\n",
        "        if  currProb > maxProbability:\n",
        "          maxProb = currProb\n",
        "          chosen_letter = currLetter\n",
        "\n",
        "    return chosen_letter\n",
        "\n",
        "# Run the game\n",
        "hangman_game(bayesian_inference)\n",
        "from typing import Optional, Callable\n",
        "# from tqdm import tqdm\n",
        "\n",
        "def benchmark(\n",
        "    inference: Optional[Callable],\n",
        "    num_runs: int = 1000,\n",
        "    seed: int = 0\n",
        ") -> None:\n",
        "    '''\n",
        "    Benchmark method for testing out the bayesian inference method. The parameters given are:\n",
        "\n",
        "    - inference: The function that should match the bayesian_inference() method above.\n",
        "    - seed: The seed to pass into the hangman_game function.\n",
        "\n",
        "    Return type: none.\n",
        "\n",
        "    Print the accuracy out of num_runs. If the function throws an error, it should count as a fail.\n",
        "    '''\n",
        "    # TODO: Implement benchmark testing for a given function\n",
        "    # Hint: pass `seed = seed` into the hangman_game function to standardize the generated words.\n",
        "    # Hint: pass `interactive = False` into the hangman_game function to run faster without outputs.\n",
        "    # Optional: use the `tqdm` module to keep track of the evaluation progress.\n",
        "\n",
        "benchmark(random_inference)\n",
        "benchmark(bayesian_inference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDq0vtR_r-V2"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Callable\n",
        "# from tqdm import tqdm\n",
        "\n",
        "def benchmark(\n",
        "    inference: Optional[Callable],\n",
        "    num_runs: int = 1000,\n",
        "    seed: int = 0\n",
        ") -> None:\n",
        "    '''\n",
        "    Benchmark method for testing out the bayesian inference method. The parameters given are:\n",
        "\n",
        "    - inference: The function that should match the bayesian_inference() method above.\n",
        "    - seed: The seed to pass into the hangman_game function.\n",
        "\n",
        "    Return type: none.\n",
        "\n",
        "    Print the accuracy out of num_runs. If the function throws an error, it should count as a fail.\n",
        "    '''\n",
        "    # TODO: Implement benchmark testing for a given function\n",
        "    # Hint: use `random.seed(seed)` ONCE at the start\n",
        "    # Hint: pass `interactive = False` into the hangman_game function to run faster without outputs.\n",
        "    # Optional: use the `tqdm` module to keep track of the evaluation progress.\n",
        "\n",
        "benchmark(random_inference)\n",
        "benchmark(bayesian_inference)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}